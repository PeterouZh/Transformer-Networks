# Transformer-Networks

PyTorch implementation of transformer networks

## Transformer
|  Title  |   Venue  |Code|Year|
|:--------|:--------:|:--------:|:--------:|
| [ConTNet: Why Not Use Convolution and Transformer at the Same Time?](http://arxiv.org/abs/2104.13497) | arXiv:2104.13497 [cs] |  | 2021 |
| [Emerging Properties in Self-Supervised Vision Transformers](http://arxiv.org/abs/2104.14294) | arXiv:2104.14294 [cs] |  | 2021 |
| [VATT: Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text](http://arxiv.org/abs/2104.11178) | arXiv:2104.11178 [cs, eess] |  | 2021 |
| [VidTr: Video Transformer Without Convolutions](http://arxiv.org/abs/2104.11746) | arXiv:2104.11746 [cs] |  | 2021 |
| [Visformer: The Vision-Friendly Transformer](http://arxiv.org/abs/2104.12533) | arXiv:2104.12533 [cs] |  | 2021 |
| [ImageNet-21K Pretraining for the Masses](http://arxiv.org/abs/2104.10972) | arXiv:2104.10972 [cs] |  | 2021 |
| [So-ViT: Mind Visual Tokens for Vision Transformer](http://arxiv.org/abs/2104.10935) | arXiv:2104.10935 [cs] |  | 2021 |
| [Token Labeling: Training a 85.4% Top-1 Accuracy Vision Transformer with 56M Parameters on ImageNet](http://arxiv.org/abs/2104.10858) | arXiv:2104.10858 [cs] |  | 2021 |
| [Going Deeper with Image Transformers](http://arxiv.org/abs/2103.17239) | arXiv:2103.17239 [cs] |  | 2021 |
| [Transformer Interpretability Beyond Attention Visualization](http://arxiv.org/abs/2012.09838) | arXiv:2012.09838 [cs] | [github](https://github.com/hila-chefer/Transformer-Explainability) | 2020 |
| [Rethinking Spatial Dimensions of Vision Transformers](http://arxiv.org/abs/2103.16302) | arXiv:2103.16302 [cs] | [github](https://github.com/naver-ai/pit) | 2021 |
| [Stand-Alone Self-Attention in Vision Models](http://arxiv.org/abs/1906.05909) | NeurIPS | [github](https://github.com/leaderj1001/Stand-Alone-Self-Attention) | 2019 |
| [Scaling Local Self-Attention For Parameter Efficient Visual Backbones](http://arxiv.org/abs/2103.12731) | arXiv:2103.12731 [cs] |  | 2021 |
| [Swin Transformer: Hierarchical Vision Transformer Using Shifted Windows](http://arxiv.org/abs/2103.14030) | arXiv:2103.14030 [cs] | [github](https://github.com/microsoft/Swin-Transformer) | 2021 |
| [Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions](http://arxiv.org/abs/2102.12122) | arXiv:2102.12122 [cs] | [github](https://github.com/whai362/PVT), [PVT_Small](exp/PVT/pvt.py) | 2021 |

## Unsupervised
|  Title  |   Venue  |Code|Year|
|:--------|:--------:|:--------:|:--------:|
| [A Large-Scale Study on Unsupervised Spatiotemporal Representation Learning](http://arxiv.org/abs/2104.14558) | arXiv:2104.14558 [cs] |  | 2021 |

## CNN
|  Title  |   Venue  |Code|Year|
|:--------|:--------:|:--------:|:--------:|
| [CondenseNet V2: Sparse Feature Reactivation for Deep Networks](http://arxiv.org/abs/2104.04382) | arXiv:2104.04382 [cs] |  | 2021 |


## Meeting
|  Title  |   Venue  |Code|Year|
|:--------|:--------:|:--------:|:--------:|
| [Dynamic Convolution: Attention over Convolution Kernels](http://arxiv.org/abs/1912.03458) | arXiv:1912.03458 [cs] |  | 2020 |
| [CondConv: Conditionally Parameterized Convolutions for Efficient Inference](http://arxiv.org/abs/1904.04971) | arXiv:1904.04971 [cs] |  | 2019 |
| [Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification](http://arxiv.org/abs/1502.01852) | arXiv:1502.01852 [cs] |  | 2015 |



